
https://github.com/Kixiron/rust-langdev


fn +(a: str, b: int) {}


#1{
  a

  #2{

    #3{

      fn bla(b) #4{
        a + b
      }
    }
  }
}

- scopes only live at compile-time


- resolve_overload()
  -? also only lives at compile-time?
  -> no, because of dynamic typing
  .. but I could pre-compile a decision tree


- how complicated is SSA?
  - while computing expressions -> easy, automatic
  - ah, only actual variables are affected, of course
    -> so then we'll turn every variable into an alloca


- how can i make it compositional?



Document = { body: Block }
Block = { items: Item[], stmts: Stmt[] }
Item =
  | NamedFn { name: Identifier, params: Declarable[], body: Block }
Declarable = { pattern: DeclarePattern, fallback?: Expr }
DeclarePattern =
  | Declare { guard: DeclareGuardExpr, ty?: Type }
  | List { element: Declarable[], rest?: { id: Identifier, type?: Type } }
  | Tuple { element: Declarable[], rest?: { id: Identifier, type?: Type } }
AssignPattern =
  | Id { id: Identifier }
  | Index { pattern: AssignPattern, expr?: Expr }
  | List { elements: AssignPattern[] } -- ..maybe later also add spread
  | Tuple { elements: AssignPattern[] } -- ..maybe later also add spread
Stmt =
  | Break { expr?: Expr }
  | Continue { label?: Identifier }
  | Return { expr?: Expr }
  | Declare { pattern: DeclarePattern, expr: Expr }
  | Assign { pattern: AssignPattern, expr: Expr }
  | Expr { expr: Expr }
Expr =
  | StrLiteral { pieces }
  | NilLiteral
  | ...



let some_digit = 5

fn solve(input: str) {
  let digits = [2, 5, some_digit]

  fn convert_base(hand) {
    hand :chars :reverse :enumerate
      :map |(i, d)| { digits[d] << (i * 4) }
      :sum
  }
}



context:
  scopes: HashMap<id, Scope = { parent_id, vars: HashMap<id, Type> }>



-> turn every closure scope into a struct on the heap
  closure = { parent, data(known exact layout) }

(module)       0: { parent: NULL, data: { some_digit } }
(solve)        1: { parent: 0,    data: { input(N/A), digits } }
(convert_base) 2: { parent: 1,    data: { hand(N/A) } }
(*inline*)     3: { parent: 2,    data: { i(N/A), d(N/A) }}

-> a function value also has a pointer to parent closure scope
  fn = { code_ptr, parent_closure_ptr }
  .. or multiple even? -- a fixed size array?
  .... or I could even just trim this down to the parent closures I even need access to in the first place?


CODEGEN(
  expr: |(i, d)| { digits[d] << (i * 4) },
  parent_scopes_shapes: [
    module: { some_digit },
    solve: { input, digits },
    convert_base: { hand },
  ]
):
  # how to access digits? we know it's in the second parent,
  #   .. but how to get to it at runtime?

  define dyn @anonymous_fn(%module_closure* %0, %solve_closure* %1, %convert_base_closure* %2, i, d) {
    %digits_ptr = getelementptr %solve_closure, %solve_closure* %1, i64 0, i64 1
    %digits = load dyn, dyn* %digits_ptr
  }


Codegen
  evaluate(curr_scope_id, expr)
    match expr {
      bool(b) -> {
        emit: %expr = i1 {b}
      }
      nil -> {
        emit: %expr = i1 0
      }
      str(pieces) -> {
        emit: %pieces = alloca [N x %dyn]

        for piece, i in pieces {
          let tmp_name = evaluate(curr_scope_id, pieces[i])

          emit: %el_{i}_ptr = getelementptr [N x %dyn], [N x %dyn]* %pieces, i64 0, i64 {i}
          emit: store dyn {tmp_name}, i32* %el_{i}_ptr
        }

        emit: %expr = call dyn @join_str_literal_pieces([N x %dyn] %pieces)
      }
      anonymous_fn(fn = {params, body}) -> {
        # 1. define function body
        # (see above for how to deal with lexical scope variable access...)
        emit: define dyn @anonymous_fn(...parent_closures, ...{...params}) {
          # 1.1. create new own closure
          let closure_type = Codegen::get_closure_type(fn)
          let size = closure_type.size_of() -- inkwell knows this
          emit: %my_closure_ptr = call ptr @malloc({size})

          # 1.2. populate the closure
          # (we could choose to only store relevant data inside, but that's a lot of bookkeeping,
          #  for now let's just use the closure for all of the scope)
          for param of params {
            emit: %param_{i}_ptr = getelementptr {closure_type}, {closure_type}* %my_closure_ptr, i64 0, i64 {i}
            emit: store dyn {tmp_name}, i32* %param_{i}_ptr
          }
        }

        # 2. compute and register runtime closure layout/type
        let vars_in_closure = ..params (but we could maybe reduce this later)
        let layout = { ... }
        emit: %anonumous_fn_closure = type { ... }
        Codegen::register_closure_type(fn, { name: "%anonumous_fn_closure", layout })
      }
      invoke(fn_expr, postfix (TODO), coalesce (TODO), arg_exprs) -> {
        let fn = evaluate(curr_scope_id, fn_expr)
        let args = arg_exprs.map(expr => evaluate(curr_scope_id, expr))

        let closure_pointer_names = []
        let curr_scope = self.get_scope(curr_scope_id)
        while let Some(scope) = curr_scope {
          closure_pointer_names.push(scope.ptr_id) // e.g. %my_closure_ptr
          curr_scope = self.get_scope(scope.parent_id)
        }

        emit: %expr = call dyn {fn}(...{...closure_pointer_names}, ...{...args})

        # ^^ this assumes that there's an unambiguous function,
        #  but if we add overloading, it's more complicated..
      }
    }



HOW TO REPRESENT VALUES .. in Rust, mostly

option 1 -- tagged union with struct + union type

  #[repr(C)]
  struct Value {
    tag: ValueType, -- simple rust tag enum
    data: ValueData,
  }

  #[repr(C)]
  union ValueData {
    bool: bool,
    int: i64,
    ...
  }



.. actually, the type is not as easy as a tag -- because e.g. concrete function types, polymorphic function types, typed arrays, etc.

#[derive(Debug, Clone, PartialEq)]
pub enum Value {
  Nil,
  Bool(bool),
  Int(Int),
  Float(Float),
  Str(Substr),
  Regex(AlRegex),
  FnDef(FnDef),
  List(Type, Vec<usize>),
  Tuple(Option<Vec<Type>>, Vec<usize>),
  Dict(Option<(Type, Type)>, Dict),
}


- how to encode value types?
  88 88 88 88 + 88 pp
  \---------/
    64 bits

  - [...type, data] -- array! clever, no?
    [true,   "bool"]
    [_,      "nil"]
    [->str,  "str"]
    [42,     "int"]
    [->fn,   "fn(3)", "arg1", "arg2", "arg3", "ret"]
    [->data, "list", "tuple", "int"]
    ...
    - pros?
      - uniform
    - cons?
      - if dynamic size -> needs to be allocated on the heap, so then it becomes pointless because it loses its win on performance

  - { type, data } -- but what about complicated types? (it needs an escape hatch, right?)
      0   nil
      1   bool
     10   int
     11   float
    100   str
    101

    ppppppCC CC------ -------- --------

    data size:
    nil           0
    bool          1
    int          64
    float        64
    str          64 (ptr)
    regex        64 (ptr)
    fn        2x 64 (closure ptr + code ptr) -- but maybe I'll store the code ptr in the closure
    list         64 (ptr)
    tuple        64 (ptr)
    dict         64 (ptr)

    -> use (10 of) 16 bits for the type + 64 bits of data

    - is it necessary to add the nested types? e.g. [int] is a list, but do we also need to add "int"?
      -> no, because it'll be in the children
      ... but then what if the list is empty? does it matter, then?

        fn bla() -> [int] {
          []
        }

        fn poly(input: [int])  { true }
        fn poly(input: [any]) { false }

        poly(bla()) -- will give an unexpected result (false instead of true)

  - V8-style:

    1..(...63 bits) -> pointer to an object on the heap with full info
    0.. -> quick simple value type(s)
      -- only small ints? and make booleans and nil heap singletons like in v8?

    000 =  nil
    001 = bool
    010 = int
    011 = float
    100 = str
    101 = regex
    110
    111
    ... fn, list, tuple, dict

    ..no, let's just go with V8's wisdom and only represent small numbers this way

......
......
... maybe this is not the fight I actually want to fight, btw
......
... maybe I should just statically type the variables, infer them where necessary,
     and select overloads at compile-time like Rust would.
    Because, truthfully, it's not like I was really intending to crazy dynamic things..
    I just wanted Rust-like syntax, but more flexibility:
    - overloads are flexible, regardless of when they're resolved
    - GC is flexible
    - :map,:find -style infix function notation is flexible
    - easy use of closures is flexible
    
    ..and selecting overloads at runtime due to unknown dynamic types is less important to me.


let cache: dict<([str], [int]), int> = {}

fn arrangements(pieces, ns, indent) {
  let h = (pieces, ns)

  if should_memoize {
    if let memoized = cache[h] {
      return memoized + 0
    }
  }
}





generic types & instantiation



It turns out that in order to check whether/how you can "instantiate" a generic type,
 you need to include subtyping checks, to select either the narrowest or widest type
 for certain type var instantiations


So now I'm wondering, are these maybe actually the same checks? Or .. should I connect
 the two problems? Checking whether a type is wider than another, and checking whether
 it can be instantiated into the other?

 If so, the sigature would be something like:

 type.can_narrow_to(other_type) -> Option<{ instantiations, }>


t                        int                        yes, with t=int
t | int                  int                        yes, with t=int

(t, t)                   (int, any)                 yes, with t=int -- because it's narrower than `any`

fn<t>() -> (t, t)        fn() -> (int, any)         yes, with t=int

[(t, t)]                 list

fn<t>(t, t)              fn(int, any)               yes, with t=any

fn<t>(t, fn<t>() -> t)   fn(bool, fn() -> int)      yes, with outer t=bool, inner t=int

fn<t>(t, fn<s>(s))       fn(bool, fn(int))          yes, with t=bool

fn<s>() -> (s, s)        fn<t>() -> (t, int)

  ^^ what to do with nested generic functions? do they also need to be instantiated?



HOW TO DO TYPE INFERENCE?
===

- function bodies are the unit of closures
- but lexical blocks determine visibility

let's say we go from top, down
then per function body we build up a scope with typings that start untyped and are narrowed down progressively
  <closure>.check_narrowing_assignment(...)




%Tp = type {
    i32,
    i1
}

define i32 @main() {
    %bit = alloca i1
    store i1 0, ptr %bit

    %int = alloca i32
    store i32 263, ptr %int

    %tup = alloca %Tp
    %field_1 = getelementptr %Tp, %Tp* %tup, i32 0, i32 1
    %bit_val = load i1, ptr %bit
    store i1 %bit_val, i1* %field_1

    %2 = mul nsw i32 1, 4
    ret i32 %2
}



let num = 42;

fn increment() {
  num += 2;

  num
}

====>>>>

fn main() {
  let num = 42;
}




either a fn is a (closure_ptr, fn_ptr) and you call it as *fn_ptr(closure_ptr, ...)
or the closure_ptr is always lying around, to be passed to the fn_ptr



fn bla() {                      -- bla     = ( &{num=42}, &bla_code )
  let num = 42;

  fn mk_inc() {                 -- mk_inc  = ( &{num=42}, &{}, &mk_inc_code )
    return |n| {                -- anon    = ( &{num=42}, &{}, &{n}, &anon_code )
      num += n;
      return num
    }
  }

  let f = mk_inc();             -- f       = ( &{num=42}, &{}, &{n}, &anon_code )
  f(10);                        -- call anon_code w/ ( &{num=42}, &{}, &{n}, 10 )
}

bla()





====
https://godbolt.org/z/zzf7frWjz

define i64 @main() {
  ret i64 500
  ; ret i64 500 -> Program returned: 244
  ; ret i64 512 -> Program returned: 0
  ; what the hell??
}

..but it's actually just because return values are mod 255 :)
====





For each function (item or inline), we need to know (and build at runtime):

- it's type (args and return)
  - in the case of a generic function:
    - every instantiation that is used




For each variable:
  - if it's a fn argument
    -> it's index
      - ...or how to get to it in case of a pattern
  - if it's a local
    - if it's not used in nested functions
      -> %-name
    - if it is
      -> it's location within .. -- how to encode? just a pointer? or a struct ptr + index? or just an index, because the ptr is lying around?
  - if it's a parent scope's variable
    -> ...





===

  let bla = 42;

  fn solve(input) {
    let values = input :lines :map |line: str| {
      let digits = line :chars :filter |c| { is_digit(c) }
      int(digits[0] + digits[-1] + bla)
    }

    values :sum
  }

  solve("someinputstr")

==>

  fn (stdlib) map<A, B>(arr: [A], f: fn(A) -> B, ... closure_ptrs: **ptr) -> [B] {
    [...]
  }

  fn $anonfilter(c: char, ... $global_closure_ptr: ptr, $solve_closure_ptr: ptr, $anonmap_closure_ptr: ptr) {
    let $res = is_digit(c)

    return $res
  }

  fn $anonmap(line: str, ... $global_closure_ptr: ptr, $solve_closure_ptr: ptr) {
    -- create a closure for all escaping locals
    let $my_closure_ptr = {}

    let $chars = chars(line)
    let digits = filter($chars, $anonfilter, ... $global_closure_ptr, $solve_closure_ptr, $my_closure_ptr)
    let $x = digits[0]
    let $y = digits[-1]
    let $z = $global_closure_ptr.bla
    let $sum = $x + $y + $z
    let $res = int($sum)

    return $res
  }

  fn solve(input: str, ... $global_closure_ptr: ptr) {
    -- create a closure for all escaping locals
    let $my_closure_ptr = {}
    $my_closure_ptr.input = input

    let $lines: [str] = lines($my_closure_ptr.input)
    let values: [int] = map($lines, $anonmap, ... $global_closure_ptr, $my_closure_ptr);
    let $sum = sum(values)

    -- if there'd be a reassignment of `input` and another function call afterwards,
    --  we'd create a new ("shadowing") closure scope beforehand

    return $sum
  }

  fn main() {
    let $global_closure_ptr = {}
    $global_closure_ptr.bla = 42;

    solve("someinputstr", ... $global_closure_ptr)

    return 0
  }

===



#FNREF

What about assigning and passing around fn references?
  ...and how it relates to overloads?

The "ideal" situation would be to be able to resolve a fn "as an overloaded fn",
  or just as a regular variable, so that after re-assigning and/or passing it around,
  it behaves the same as "where it came from" (right?)

But, because assignment is a runtime thing, this cannot work.

One solution: only allow invocations of names.
  But then we lose:
    - higher-order fn passing, as arguments to e.g. `map` or `filter` -- can't go here
    - 

So then .. maybe we just always resolve the fn to a specific overload,
  when we pass/assign/call it?
The overload would be specified, but, it could still be a generic function
  (so still might need to be instantiated)



let inc = 5;

fn inc(n: int) -> int { ... }

fn inc(c: char) -> char { ... }

// inc :: (fn(int) -> int) | (fn(char) -> char)

// fn get_inc() {
//   if true {
//     inc
//   } else {
//     |s: str| { s }
//   }
// }

fn get_inc() {
  inc
}

fn main() {
  let m = get_inc()
  // or
  let m = inc

  // how to resolve `m` ?
  // it's a variable, but it doesn't refer to a function,
  //  instead it's a local in scope, that happens to, at runtime,
  //  be resolved to a function
  print("{m(42)}")
  print("{m('k')}")
}


  process_expr(Expr::Invocation { ... })
    // levels:
    // - fully static: I *now* select/resolve a concrete fn_id overload
    // - semi-static: I only know that expr_hir *will* at runtime resolve to a fn_id overload,
    //                  but I can check *now* that all possible resolutions are valid ??
    //     -- but how/when do I instantiate generic fns, and select a fn overload?
    // - fully runtime: at runtime I check the resolved type and choose an overload





#BYE-VARLEN-TUPLES

I guess I can't have variable length tuples, i.e. heterogenous lists,
 if I want to strictly type upfront,
 unless I dynamically include type tags .. bringing the whole dynamic nature back again



Type memory layout
  no relevant
    Never
    Num
    TypeVar { var }

  relevant
    Nil                       -> just     (): size =  0, align = 0x1, no Drop                           1
    Bool                      -> just   bool: size =  1, align = 0x1, no Drop                           1
    Str                       -> just String: size = 24, align = 0x8, needs Drop   (ptr, len, cap)     24
    Int                       -> just    i64: size =  8, align = 0x8, no Drop                           8
    Float                     -> just    f64: size =  8, align = 0x8, no Drop                           8
    Regex                     -> just  Regex: size = 32 (0x20), align = 0x8, needs Drop                32
    Fn                        -> just a pointer, i.e. 8 bytes                                           8
    List { el_ty }            -> just Vec<T>: size = 24, align = 0x8, needs Drop   (ptr, len, cap)     24
    Tuple { ...el_types }
    Nullable { ty }


FFI things

  Option<T> and Vec<T> are not FFI-safe

  https://stackoverflow.com/a/39270881

  https://doc.rust-lang.org/std/vec/struct.Vec.html#method.from_raw_parts

  allocators are super important -- Rust's is a different one

  mem::forget()
  Vec::from_raw_parts()

  ---

  ...and then still, LLVM turns out to be very nasty with passing and returning structures:
    https://yorickpeterse.com/articles/the-mess-that-is-handling-structure-arguments-and-returns-in-llvm/


  ---

  (!) Another radical idea:

  - I could, instead of passing around { ptr, i64, i64 } via sret(...) arguments for vecs and strings,
     or trimming it down to { ptr, bitcast { i32, i32 } as an i64 } and maybe using byval, to satisfy calling conventions,
     .. just pass around a single "domain pointer" i32/i64, an id into the GC arena of whatever system I use for heap management in Rust. Because, well, I'll need a GC system in Rust anyway.

    ..So, my options are:

     - passed and returned as    sret({ ptr, i64, i64 })     ->  extra dereferencing and heap allocations
     - trimmed down to         { ptr, { i32, i32 } as i64 }  ->  calling conventions trickiness (not sure how much)
     - domain GC id                i32/i64                   ->  


Monomorphization things

  If I want to use Rust's Vec (and just take the overhead of writing a wrapper and doing mem::forget() and Vec::from_raw_parts() etc., then I still have the problem of directing Rust to actually compile all the specific instances that I need. This is meta ... so ... impossible?)
    Unless I don't actually compile all the specific types, but just the SIZES of the types. I could, technically speaking, just hardcode-monomorphize the, say, 8 different sizes (1, 2, 8, 16, 24, 32, 48, 64 bytes), and then just bitcast in LLVM-world.

  Options:
    - write hardcoded size-directed monomorphizations in Rust, bitcast back in LLVM
    - generate the Rust code, direct the process in JS or meta-Rust somehow
      -- can this be done with macros ?? -- NO
      -- https://charlycst.github.io/posts/jit-ing-rust/
    - write implementations (of Vec<T>) in LLVM directly, only use concrete things (String, Regex) in Rust
    - "do more in C++ instead of trying to do everything in Rust"
      -- how would this look ??


Garbage collection options

  - Use the "conservative garbage collector" by Boehm: https://hboehm.info/gc/
    - I'd have to link it somehow, might be problematic.
      The upshot: I might not need to do anything else!

  - "Just use Rc"
    - it wouldn't be 100% correct, given cycles, but, I don't think I'll need cycles for most AoC challenges...

  - Use the LLVM intrinsics that help a garbage collector implementation: @llvm.gcroot, etc.
    + integrate with a GC interface/implementation on the Rust side

  - Add my own little helper calls here and there. Specifically, I'll need drops
    + integrate with a GC interface/implementation on the Rust side

  ^^ I'll probably just go for the last one though, because it requires the least research and is low-investment.

  ---

  "Using a GC library"
  https://docs.rs/safe-gc/1.1.1/safe_gc/index.html

  ---

  "Writing my own"

    - I'd write a tracing collector. I'd need to:

      - mark roots
        - a non-escaping function- local pointing to a Rust object: register as root
        - an escaping variable ptr stored in a closure:
          - the closure ptr: register a root
          - the variable: the GC needs to know how to get there, which means Rust needs to understand the memory layout of the closure

      - drop
        - non-escaping function locals: drop
        - closure ptrs: drop (if they're returned as passed on, their references are copied anyway, and so still reachable)
        - how?
          1. add code at end of fn + right before every `ret`
          2. always add an 'end' block, and let `ret` jump to that block, and use `phi` to select return value

      - what about heap moves?
        - will the moved object accidentally be collected? NO, because it's reachable
        - will the old object accidentally leak? (maybe?) (I guess not, because Rust will clean up when it moves?)

      - collect
        - somehow decide on regular intervals to trace & collect ...

      - trace
        - trace vectors
        - trace closures
        - how?
          - !! we need to know the memory layout + the types referenced
            1. store full metadata, e.g. TypeHIRs
            2. store just enough: offsets, for example:
              - closures: { type: CLOSURE, *parent, *gc_offsets, ...locals }
              - vectors: { type: VECTOR, element_size, length, capacity, *rust_vec }

  ---

Type memory layout

  relevant
    nil                             8 (0)  -- for compatibility, instead of i0/void
    bool                            8 (0/1) -- for compatibility, instead of i1
    int                            64
    float                          64

    str,regex,fn,list         ptr (64)

    ?nil = nil

    ?bool                           8  -- we'll just pack the nullability into another bit
    ?int                           64  -- I'll use the MSB to mark and check for nil
    ?float                         64  -- I'll use a NaN pattern like f64::NAN and .is_nan()

    ?{str,regex,fn,list}      ptr (64) -- it can just be a nill-pointer

    I'll have to think some more about how to deal with:

    tuple(...)
    ?tuple(...)
